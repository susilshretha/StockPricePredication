{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23ffb122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f848351",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m Lstm_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM_prediction.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m RF_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy_random_forest.joblib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py:507\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds)\u001b[0m\n\u001b[0;32m    502\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    503\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    504\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    505\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    506\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 507\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py:220\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    219\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 220\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    222\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "Lstm_model = load_model(\"LSTM_prediction.h5\")\n",
    "RF_model = load_model(\"my_random_forest.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lstm_data = pd.read_csv(\"AAPL-Final.csv\")\n",
    "RF_data=pd.read_csv(\"AAPL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e39b9aef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RF_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m allmodels \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLong Short Term Memory\u001b[39m\u001b[38;5;124m'\u001b[39m: Lstm_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest Model\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mRF_model\u001b[49m}\n\u001b[0;32m      2\u001b[0m stocks \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLong Short Term Memory\u001b[39m\u001b[38;5;124m'\u001b[39m: Lstm_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom Forest Regressor\u001b[39m\u001b[38;5;124m'\u001b[39m:RF_data}\n\u001b[0;32m      3\u001b[0m stocks_data \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApple with External Parameter\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApple historical data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RF_model' is not defined"
     ]
    }
   ],
   "source": [
    "allmodels = {'Long Short Term Memory': Lstm_model, 'Random Forest Model':RF_model}\n",
    "stocks = {'Long Short Term Memory': Lstm_data, 'Random Forest Regressor':RF_data}\n",
    "stocks_data = ('Apple with External Parameter','Apple historical data')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d88b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 30\n",
    "\n",
    "def choose_dataset(stocks, stocks_data, allmodels):\n",
    "    st.sidebar.subheader('Select the bank')\n",
    "    stock = st.sidebar.selectbox( \"\", stocks_data, key='1' )\n",
    "    check = st.sidebar.checkbox(\"Hide\", value=True, key='1')\n",
    "    \n",
    "    \n",
    "    #st.sidebar.write(check)\n",
    "    for itr in stocks_data:\n",
    "        if stock==itr:\n",
    "            main_df=stocks[itr]\n",
    "            model=allmodels[itr]\n",
    "    return main_df, check, stock, model\n",
    "\n",
    "\n",
    "def about_section():\n",
    "    st.sidebar.subheader('Made By:')\n",
    "    st.sidebar.markdown(\"Mrinab Dey\")\n",
    "    st.sidebar.markdown('[LinkedIn](https://www.linkedin.com/in/mrinabdey/) [Github](https://github.com/mrinabdey)', unsafe_allow_html=True)\n",
    "    st.sidebar.markdown(\"Pankaj Kumar Sah\")\n",
    "    st.sidebar.markdown('[LinkedIn](https://www.linkedin.com/in/pankaj-sah-b7aa39186/) [Github](https://github.com/52punk)', unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "    \n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "def plot_predict(df, model, name):\n",
    "    df = df.drop([\"Open\", \"Low\", \"Adj Close\", \"Volume\"], axis=1)\n",
    "    df = df.dropna()\n",
    "    Date = df[\"Date\"]\n",
    "    close = df[\"Close\"]\n",
    "    close = close.dropna()\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    tmp = scaler.fit(np.array(close).reshape(-1,1))\n",
    "    new_df = scaler.transform(np.array(close).reshape(-1,1))\n",
    "\n",
    "    training_size=int(len(new_df)*0.67)\n",
    "    test_size=len(new_df)-training_size\n",
    "    train_data,test_data=new_df[:training_size],new_df[training_size:]\n",
    "    Date_train, Date_test = Date[:training_size], Date[training_size:]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    n_steps = 30\n",
    "    time_step=n_steps\n",
    "    X_train, Y_train = create_dataset(train_data, time_step)\n",
    "    X_test, Y_test = create_dataset(test_data, time_step)\n",
    "    print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)\n",
    "    X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
    "    print(X_train.shape, X_test.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_predict=model.predict(X_train)\n",
    "    test_predict=model.predict(X_test)\n",
    "    print(train_predict.shape, test_predict.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(f'Train error - {mean_squared_error(train_predict, Y_train)*100}')\n",
    "    print(f'Test error - {mean_squared_error(test_predict, Y_test)*100}')\n",
    "    \n",
    "    \n",
    "    train_predict=scaler.inverse_transform(train_predict)\n",
    "    test_predict=scaler.inverse_transform(test_predict)\n",
    "    X_train=X_train.reshape(-1, 1)\n",
    "    X_test=X_test.reshape(-1, 1)\n",
    "    close_train=scaler.inverse_transform(train_data)\n",
    "    close_test=scaler.inverse_transform(test_data)\n",
    "    close_train = close_train.reshape(-1)\n",
    "    close_test = close_test.reshape(-1)\n",
    "    prediction = test_predict.reshape((-1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    trace1 = go.Scatter(\n",
    "        x = Date_train,\n",
    "        y = close_train,\n",
    "        mode = 'lines',\n",
    "        name = 'Data'\n",
    "    )\n",
    "    trace2 = go.Scatter(\n",
    "        x = Date_test[n_steps:],\n",
    "        y = prediction,\n",
    "        mode = 'lines',\n",
    "        name = 'Prediction'\n",
    "    )\n",
    "    trace3 = go.Scatter(\n",
    "        x = Date_test,\n",
    "        y = close_test,\n",
    "        mode='lines',\n",
    "        name = 'Ground Truth'\n",
    "    )\n",
    "    layout = go.Layout(\n",
    "        title = name,\n",
    "        xaxis = {'title' : \"Date\"},\n",
    "        yaxis = {'title' : \"Close\"}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fig = go.Figure(data=[trace1, trace2, trace3], layout=layout)\n",
    "    \n",
    "    st.plotly_chart(fig)\n",
    "    #fig.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353914cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_forecast_data(df, days, model, name):\n",
    "    \n",
    "    df = df.drop([\"Open\", \"Low\", \"Adj Close\", \"Volume\"], axis=1)\n",
    "    df = df.dropna()\n",
    "    Date = df[\"Date\"]\n",
    "    close = df[\"Close\"]\n",
    "    close = close.dropna()\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    tmp = scaler.fit(np.array(close).reshape(-1,1))\n",
    "    new_df = scaler.transform(np.array(close).reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_data = close\n",
    "    test_data = scaler.transform(np.array(close).reshape(-1,1))\n",
    "    test_data = test_data.reshape((-1))\n",
    "    \n",
    "    \n",
    "    def predict(num_prediction, model):\n",
    "        prediction_list = test_data[-n_steps:]\n",
    "        \n",
    "        for _ in range(num_prediction):\n",
    "            x = prediction_list[-n_steps:]\n",
    "            x = x.reshape((1, n_steps, 1))\n",
    "            out = model.predict(x)[0][0]\n",
    "            prediction_list = np.append(prediction_list, out)\n",
    "        prediction_list = prediction_list[n_steps-1:]\n",
    "            \n",
    "        return prediction_list\n",
    "    \n",
    "    \n",
    "    def predict_dates(num_prediction):\n",
    "        last_date = df['Date'].values[-1]\n",
    "        prediction_dates = pd.date_range(last_date, periods=num_prediction+1).tolist()\n",
    "        return prediction_dates\n",
    "    \n",
    "    num_prediction =days\n",
    "    forecast = predict(num_prediction, model)\n",
    "    forecast_dates = predict_dates(num_prediction)\n",
    "    forecast = forecast.reshape(1, -1)\n",
    "    forecast = scaler.inverse_transform(forecast)\n",
    "    forecast\n",
    "    test_data = test_data.reshape(1, -1)\n",
    "    test_data = scaler.inverse_transform(test_data)\n",
    "    test_data = test_data.reshape(-1)\n",
    "    forecast = forecast.reshape(-1)\n",
    "    res = dict(zip(forecast_dates, forecast))\n",
    "    date = df[\"Date\"]\n",
    "    \n",
    "    trace1 = go.Scatter(\n",
    "        x = date,\n",
    "        y = test_data,\n",
    "        mode = 'lines',\n",
    "        name = 'Data'\n",
    "    )\n",
    "    trace2 = go.Scatter(\n",
    "        x = forecast_dates,\n",
    "        y = forecast,\n",
    "        mode = 'lines',\n",
    "        name = 'Prediction'\n",
    "    )\n",
    "    layout = go.Layout(\n",
    "    title = name,\n",
    "    xaxis = {'title' : \"Date\"},\n",
    "    yaxis = {'title' : \"Close\"}\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fig = go.Figure(data=[trace1, trace2], layout=layout)\n",
    "    st.plotly_chart(fig)\n",
    "    #fig.show()\n",
    "    choose_date = st.selectbox(\"Date\", forecast_dates)\n",
    "    for itr in res:\n",
    "        if choose_date==itr:\n",
    "            res_price=res[itr]\n",
    "    st.write(f\"On {choose_date} the stock price will be Rs. {res_price}\")\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ab5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw_data(data):\n",
    "    \n",
    "   \tfig = go.Figure()\n",
    "   \tfig.add_trace(go.Scatter(x=data['Date'], y=data['Open'], name=\"stock_open\"))\n",
    "   \tfig.add_trace(go.Scatter(x=data['Date'], y=data['Close'], name=\"stock_close\"))\n",
    "   \tfig.layout.update( xaxis_rangeslider_visible=True)\n",
    "   \tst.plotly_chart(fig)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c81af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landing_ui():\n",
    "    st.header(\"Welcome to Stock Price Predictor\")\n",
    "    st.write(\"\")\n",
    "    st.write(\"\")\n",
    "    st.write(\"Welcome to this site\")\n",
    "    st.write(\"As the model is trained with data having time steps of 30 days so it will give its best results for a forecast till 30days \")\n",
    "    st.write(\"\")\n",
    "    st.write(\"To see the data representation please uncheck the hide button in the sidebar\")\n",
    "    st.write(\"\")\n",
    "    st.write(\"Share market investments are subject to market risks, read all scheme related documents carefully. The NAVs of the schemes may go up or down depending upon the factors and forces affecting the securities market including the fluctuations in the interest rates. The past performance of the stocks is not necessarily indicative of future performance of the schemes.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59712c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 19:50:12.734 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\offic\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStock Market Predictor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m st\u001b[38;5;241m.\u001b[39msidebar\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m temp, check, name, model\u001b[38;5;241m=\u001b[39mchoose_dataset(\u001b[43mstocks\u001b[49m, stocks_data, allmodels)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#about_section()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#print(temp)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stocks' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    st.sidebar.subheader(\"Stock Market Predictor\")\n",
    "    st.sidebar.markdown(\"---\")\n",
    "    temp, check, name, model=choose_dataset(stocks, stocks_data, allmodels)\n",
    "    #about_section()\n",
    "    #print(temp)\n",
    "    if not check:\n",
    "        st.header(f\"Analyzing {name}'s stock data\")\n",
    "        st.subheader(\"Raw Data\")\n",
    "        st.write(temp)\n",
    "        \n",
    "        \n",
    "        st.subheader(\"Raw Data - Visualized\")\n",
    "        plot_raw_data(temp)\n",
    "        st.subheader(\"Predicted data\")\n",
    "        plot_predict(temp, model, name)\n",
    "        st.sidebar.subheader(\"Forecasted Data\")\n",
    "        forecast_check = st.sidebar.checkbox(\"See the results\", value=False)\n",
    "        about_section()\n",
    "        if forecast_check:\n",
    "            forecast = st.slider(\"Days to forecast\",min_value=30,max_value=100,step=5)\n",
    "            st.subheader(\"Forecasted data\")\n",
    "            \n",
    "            plot_forecast_data(temp, forecast, model, name)\n",
    "    else:\n",
    "        landing_ui()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071a27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a48941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
