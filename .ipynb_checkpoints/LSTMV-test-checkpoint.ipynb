{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3142,
     "status": "ok",
     "timestamp": 1662651722816,
     "user": {
      "displayName": "Abhiyantraka",
      "userId": "08575671547903053425"
     },
     "user_tz": -345
    },
    "id": "ua4lzqY-nbV5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1699,
     "status": "ok",
     "timestamp": 1662651724499,
     "user": {
      "displayName": "Abhiyantraka",
      "userId": "08575671547903053425"
     },
     "user_tz": -345
    },
    "id": "ln0FVRoUndp4",
    "outputId": "299f8316-372c-409d-c693-4a79906290b8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>eps</th>\n",
       "      <th>p/e</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Inflation_rate</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2000</td>\n",
       "      <td>0.936384</td>\n",
       "      <td>1.004464</td>\n",
       "      <td>0.907924</td>\n",
       "      <td>11.324009</td>\n",
       "      <td>18.149305</td>\n",
       "      <td>3.411051</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>0.999442</td>\n",
       "      <td>0.853355</td>\n",
       "      <td>535796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2000</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.987723</td>\n",
       "      <td>0.903460</td>\n",
       "      <td>9.778793</td>\n",
       "      <td>17.445471</td>\n",
       "      <td>2.796146</td>\n",
       "      <td>2.488276</td>\n",
       "      <td>0.915179</td>\n",
       "      <td>0.781409</td>\n",
       "      <td>512377600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2000</td>\n",
       "      <td>0.926339</td>\n",
       "      <td>0.987165</td>\n",
       "      <td>0.919643</td>\n",
       "      <td>9.422680</td>\n",
       "      <td>17.327946</td>\n",
       "      <td>2.795518</td>\n",
       "      <td>2.488011</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.792844</td>\n",
       "      <td>778321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2000</td>\n",
       "      <td>0.947545</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>7.335150</td>\n",
       "      <td>22.874871</td>\n",
       "      <td>2.794891</td>\n",
       "      <td>2.487746</td>\n",
       "      <td>0.848214</td>\n",
       "      <td>0.724232</td>\n",
       "      <td>767972800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2000</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>26.008772</td>\n",
       "      <td>2.198084</td>\n",
       "      <td>2.794264</td>\n",
       "      <td>2.487482</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.758538</td>\n",
       "      <td>460734400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Open      High       Low        eps        p/e  \\\n",
       "0  1/3/2000  0.936384  1.004464  0.907924  11.324009  18.149305   \n",
       "1  1/4/2000  0.966518  0.987723  0.903460   9.778793  17.445471   \n",
       "2  1/5/2000  0.926339  0.987165  0.919643   9.422680  17.327946   \n",
       "3  1/6/2000  0.947545  0.955357  0.848214   7.335150  22.874871   \n",
       "4  1/7/2000  0.861607  0.901786  0.852679  26.008772   2.198084   \n",
       "\n",
       "   Interest_Rate  Inflation_rate     Close  Adj Close     Volume  \n",
       "0       3.411051        1.760000  0.999442   0.853355  535796800  \n",
       "1       2.796146        2.488276  0.915179   0.781409  512377600  \n",
       "2       2.795518        2.488011  0.928571   0.792844  778321600  \n",
       "3       2.794891        2.487746  0.848214   0.724232  767972800  \n",
       "4       2.794264        2.487482  0.888393   0.758538  460734400  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_data = pd.read_csv('AAPL-Final.csv',index_col='Date')\n",
    "# stock_data.head()\n",
    "\n",
    "df = pd.read_csv('AAPL-Final.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1662651724504,
     "user": {
      "displayName": "Abhiyantraka",
      "userId": "08575671547903053425"
     },
     "user_tz": -345
    },
    "id": "FsBe2k28ntb3",
    "outputId": "a0e72c38-b5e1-4685-ad93-e76285f2e7e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.999442\n",
       "1         0.915179\n",
       "2         0.928571\n",
       "3         0.848214\n",
       "4         0.888393\n",
       "           ...    \n",
       "5531    180.330002\n",
       "5532    179.289993\n",
       "5533    179.380005\n",
       "5534    178.199997\n",
       "5535    177.570007\n",
       "Name: Close, Length: 5536, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stock_data.tail()\n",
    "\n",
    "df1=df.reset_index()['Close']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x183e2e4bc70>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.dates as mdates\n",
    "# plt.figure(figsize=(15,10))\n",
    "# plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "# plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=60))\n",
    "# x_dates=[dt.datetime.strptime(d,'%m/%d/%Y').date() for d in df.index.values],\n",
    "\n",
    "\n",
    "# plt.plot(x_dates, df['High'], label='High')\n",
    "# plt.plot(x_dates, df['Low'], label='Low')\n",
    "# plt.xlabel('Time Scale')\n",
    "# plt.ylabel('Scaled USD')\n",
    "# plt.legend()\n",
    "# plt.gcf().autofmt_xdate()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(df1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # target variables\n",
    "# target_y=stock_data['Close']\n",
    "# target_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature variables\n",
    "# x_feat=stock_data.iloc[:,0:7]\n",
    "# x_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "# sc=StandardScaler()\n",
    "# x_ft=sc.fit_transform(x_feat.values)\n",
    "# x_ft=pd.DataFrame(columns=x_feat.columns,data=x_ft, index=x_feat.index)\n",
    "\n",
    "#Scaling the dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00424861],\n",
       "       [0.00378073],\n",
       "       [0.00385509],\n",
       "       ...,\n",
       "       [0.99472504],\n",
       "       [0.98817293],\n",
       "       [0.98467484]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def lstm_split(data, n_steps):\n",
    "#     x,y=[],[]\n",
    "#     for i in range(len(data)-n_steps+1):\n",
    "#         x.append(data[i:i+n_steps, :-1])\n",
    "#         y.append(data[i+n_steps-1, -1])\n",
    "#     return np.array(x), np.array(y)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test sets for Stock Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x1, y1=lstm_split(stock_data.values, n_steps=2)\n",
    "\n",
    "# train_split=0.8\n",
    "# split_idx=int(np.ceil(len(x1)*train_split))\n",
    "# date_index=stock_data.index\n",
    "\n",
    "\n",
    "# x_train, x_test=x1[:split_idx], x1[split_idx:]\n",
    "# y_train, y_test=y1[:split_idx], y1[split_idx:]\n",
    "\n",
    "# x_train_date, x_test_date=date_index[:split_idx], date_index[split_idx:]\n",
    "\n",
    "\n",
    "# print(x1.shape, x_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "#spliting the dataset into train and test split\n",
    "\n",
    "training_size=int(len(df1)*0.8)\n",
    "test_size=len(df1)-training_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4428, 1108)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4428"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1108"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4327, 100)\n",
      "(4327,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape), print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1007, 100)\n",
      "(1007,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape), print(ytest.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.00424861]\n",
      "  [0.00378073]\n",
      "  [0.00385509]\n",
      "  ...\n",
      "  [0.00315792]\n",
      "  [0.00295341]\n",
      "  [0.00304637]]\n",
      "\n",
      " [[0.00378073]\n",
      "  [0.00385509]\n",
      "  [0.0034089 ]\n",
      "  ...\n",
      "  [0.00295341]\n",
      "  [0.00304637]\n",
      "  [0.00302545]]\n",
      "\n",
      " [[0.00385509]\n",
      "  [0.0034089 ]\n",
      "  [0.003632  ]\n",
      "  ...\n",
      "  [0.00304637]\n",
      "  [0.00302545]\n",
      "  [0.0029813 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.19192968]\n",
      "  [0.19163818]\n",
      "  [0.19367877]\n",
      "  ...\n",
      "  [0.20515876]\n",
      "  [0.20699113]\n",
      "  [0.21683311]]\n",
      "\n",
      " [[0.19163818]\n",
      "  [0.19367877]\n",
      "  [0.19399803]\n",
      "  ...\n",
      "  [0.20699113]\n",
      "  [0.21683311]\n",
      "  [0.21465372]]\n",
      "\n",
      " [[0.19367877]\n",
      "  [0.19399803]\n",
      "  [0.19302633]\n",
      "  ...\n",
      "  [0.21683311]\n",
      "  [0.21465372]\n",
      "  [0.215792  ]]] [[[0.22227465]\n",
      "  [0.21430669]\n",
      "  [0.21730507]\n",
      "  ...\n",
      "  [0.23551763]\n",
      "  [0.23618393]\n",
      "  [0.23361585]]\n",
      "\n",
      " [[0.21430669]\n",
      "  [0.21730507]\n",
      "  [0.22059501]\n",
      "  ...\n",
      "  [0.23618393]\n",
      "  [0.23361585]\n",
      "  [0.23782194]]\n",
      "\n",
      " [[0.21730507]\n",
      "  [0.22059501]\n",
      "  [0.22302427]\n",
      "  ...\n",
      "  [0.23361585]\n",
      "  [0.23782194]\n",
      "  [0.2377803 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.81526488]\n",
      "  [0.81015649]\n",
      "  [0.80987884]\n",
      "  ...\n",
      "  [0.97395828]\n",
      "  [0.97751194]\n",
      "  [1.        ]]\n",
      "\n",
      " [[0.81015649]\n",
      "  [0.80987884]\n",
      "  [0.80715812]\n",
      "  ...\n",
      "  [0.97751194]\n",
      "  [1.        ]\n",
      "  [0.99422524]]\n",
      "\n",
      " [[0.80987884]\n",
      "  [0.80715812]\n",
      "  [0.80860177]\n",
      "  ...\n",
      "  [1.        ]\n",
      "  [0.99422524]\n",
      "  [0.99472504]]]\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be [samples, time steps, features] \n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)   #shape[0]=4327, shape[1]=100 \n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)\n",
    "\n",
    "print(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single unit LSTM mpdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50, input_shape=(100,1),\n",
    "               activation='relu', return_sequences=True))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 50)           10400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100, 1)            51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiting the above model to trsining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1082/1082 [==============================] - 35s 31ms/step - loss: 4.0507e-05\n",
      "Epoch 2/100\n",
      "1082/1082 [==============================] - 32s 30ms/step - loss: 2.7183e-04\n",
      "Epoch 3/100\n",
      "1082/1082 [==============================] - 33s 30ms/step - loss: 2.7098e-04\n",
      "Epoch 4/100\n",
      "1082/1082 [==============================] - 33s 30ms/step - loss: 2.2390e-04\n",
      "Epoch 5/100\n",
      "1082/1082 [==============================] - 35s 32ms/step - loss: 2.0107e-04\n",
      "Epoch 6/100\n",
      "1082/1082 [==============================] - 35s 33ms/step - loss: 2.5644e-04\n",
      "Epoch 7/100\n",
      "1082/1082 [==============================] - 38s 35ms/step - loss: 2.3293e-04\n",
      "Epoch 8/100\n",
      "1082/1082 [==============================] - 43s 39ms/step - loss: 2.2125e-04\n",
      "Epoch 9/100\n",
      "1082/1082 [==============================] - 37s 34ms/step - loss: 2.3483e-04\n",
      "Epoch 10/100\n",
      "1082/1082 [==============================] - 38s 35ms/step - loss: 1.9931e-04\n",
      "Epoch 11/100\n",
      "1082/1082 [==============================] - 37s 34ms/step - loss: 1.8618e-04\n",
      "Epoch 12/100\n",
      "1082/1082 [==============================] - 38s 35ms/step - loss: 1.8071e-04\n",
      "Epoch 13/100\n",
      "1082/1082 [==============================] - 38s 35ms/step - loss: 1.5874e-04\n",
      "Epoch 14/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 1.5632e-04\n",
      "Epoch 15/100\n",
      "1082/1082 [==============================] - 40s 37ms/step - loss: 1.5735e-04\n",
      "Epoch 16/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 1.5179e-04\n",
      "Epoch 17/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 1.4764e-04\n",
      "Epoch 18/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 1.2675e-04\n",
      "Epoch 19/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 1.2319e-04\n",
      "Epoch 20/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 1.2389e-04\n",
      "Epoch 21/100\n",
      "1082/1082 [==============================] - 40s 37ms/step - loss: 1.2452e-04\n",
      "Epoch 22/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 1.2428e-04\n",
      "Epoch 23/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 1.1756e-04\n",
      "Epoch 24/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.1978e-04\n",
      "Epoch 25/100\n",
      "1082/1082 [==============================] - 40s 37ms/step - loss: 1.2163e-04\n",
      "Epoch 26/100\n",
      "1082/1082 [==============================] - 40s 37ms/step - loss: 1.2237e-04\n",
      "Epoch 27/100\n",
      "1082/1082 [==============================] - 40s 37ms/step - loss: 1.1888e-04\n",
      "Epoch 28/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.1354e-04\n",
      "Epoch 29/100\n",
      "1082/1082 [==============================] - 41s 37ms/step - loss: 1.1303e-04\n",
      "Epoch 30/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.1482e-04\n",
      "Epoch 31/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.1534e-04\n",
      "Epoch 32/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.1353e-04\n",
      "Epoch 33/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.1210e-04\n",
      "Epoch 34/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0713e-04\n",
      "Epoch 35/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0690e-04\n",
      "Epoch 36/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0682e-04\n",
      "Epoch 37/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0792e-04\n",
      "Epoch 38/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0683e-04\n",
      "Epoch 39/100\n",
      "1082/1082 [==============================] - 41s 37ms/step - loss: 1.0434e-04\n",
      "Epoch 40/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0624e-04\n",
      "Epoch 41/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0655e-04\n",
      "Epoch 42/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0669e-04\n",
      "Epoch 43/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0478e-04\n",
      "Epoch 44/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0498e-04\n",
      "Epoch 45/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0681e-04\n",
      "Epoch 46/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0543e-04\n",
      "Epoch 47/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0168e-04\n",
      "Epoch 48/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0354e-04\n",
      "Epoch 49/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 1.0393e-04\n",
      "Epoch 50/100\n",
      "1082/1082 [==============================] - 42s 38ms/step - loss: 1.0661e-04\n",
      "Epoch 51/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0148e-04\n",
      "Epoch 52/100\n",
      "1082/1082 [==============================] - 42s 38ms/step - loss: 1.0247e-04\n",
      "Epoch 53/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0287e-04\n",
      "Epoch 54/100\n",
      "1082/1082 [==============================] - 42s 38ms/step - loss: 1.0273e-04\n",
      "Epoch 55/100\n",
      "1082/1082 [==============================] - 42s 38ms/step - loss: 1.0019e-04\n",
      "Epoch 56/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0073e-04\n",
      "Epoch 57/100\n",
      "1082/1082 [==============================] - 43s 40ms/step - loss: 1.0077e-04\n",
      "Epoch 58/100\n",
      "1082/1082 [==============================] - 42s 38ms/step - loss: 1.0024e-04\n",
      "Epoch 59/100\n",
      "1082/1082 [==============================] - 43s 40ms/step - loss: 1.0039e-04\n",
      "Epoch 60/100\n",
      "1082/1082 [==============================] - 44s 40ms/step - loss: 1.0030e-04\n",
      "Epoch 61/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 1.0003e-04\n",
      "Epoch 62/100\n",
      "1082/1082 [==============================] - 43s 39ms/step - loss: 9.9157e-05\n",
      "Epoch 63/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 9.6626e-05\n",
      "Epoch 64/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 9.7875e-05\n",
      "Epoch 65/100\n",
      "1082/1082 [==============================] - 43s 40ms/step - loss: 9.8461e-05\n",
      "Epoch 66/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 9.8548e-05\n",
      "Epoch 67/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 9.8407e-05\n",
      "Epoch 68/100\n",
      "1082/1082 [==============================] - 43s 40ms/step - loss: 9.8122e-05\n",
      "Epoch 69/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 9.7582e-05\n",
      "Epoch 70/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 9.6837e-05\n",
      "Epoch 71/100\n",
      "1082/1082 [==============================] - 43s 40ms/step - loss: 9.6974e-05\n",
      "Epoch 72/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 9.6775e-05\n",
      "Epoch 73/100\n",
      "1082/1082 [==============================] - 38s 35ms/step - loss: 9.6708e-05\n",
      "Epoch 74/100\n",
      "1082/1082 [==============================] - 37s 35ms/step - loss: 9.6591e-05\n",
      "Epoch 75/100\n",
      "1082/1082 [==============================] - 56s 52ms/step - loss: 9.6333e-05\n",
      "Epoch 76/100\n",
      "1082/1082 [==============================] - 51s 47ms/step - loss: 9.6131e-05\n",
      "Epoch 77/100\n",
      "1082/1082 [==============================] - 51s 47ms/step - loss: 9.6114e-05\n",
      "Epoch 78/100\n",
      "1082/1082 [==============================] - 51s 47ms/step - loss: 9.5824e-05\n",
      "Epoch 79/100\n",
      "1082/1082 [==============================] - 50s 46ms/step - loss: 9.5736e-05\n",
      "Epoch 80/100\n",
      "1082/1082 [==============================] - 55s 51ms/step - loss: 9.5443e-05\n",
      "Epoch 81/100\n",
      "1082/1082 [==============================] - 34s 31ms/step - loss: 9.5384e-05\n",
      "Epoch 82/100\n",
      "1082/1082 [==============================] - 39s 36ms/step - loss: 9.5281e-05\n",
      "Epoch 83/100\n",
      "1082/1082 [==============================] - 40s 37ms/step - loss: 9.4884e-05\n",
      "Epoch 84/100\n",
      "1082/1082 [==============================] - 40s 37ms/step - loss: 9.4842e-05\n",
      "Epoch 85/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.4755e-05\n",
      "Epoch 86/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.4387e-05\n",
      "Epoch 87/100\n",
      "1082/1082 [==============================] - 42s 39ms/step - loss: 9.4241e-05\n",
      "Epoch 88/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.4326e-05\n",
      "Epoch 89/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.4114e-05\n",
      "Epoch 90/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.4099e-05\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.3726e-05\n",
      "Epoch 92/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.3587e-05\n",
      "Epoch 93/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.3448e-05\n",
      "Epoch 94/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.3096e-05\n",
      "Epoch 95/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.3076e-05\n",
      "Epoch 96/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.3126e-05\n",
      "Epoch 97/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.3090e-05\n",
      "Epoch 98/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.3088e-05\n",
      "Epoch 99/100\n",
      "1082/1082 [==============================] - 41s 38ms/step - loss: 9.5337e-05\n",
      "Epoch 100/100\n",
      "1082/1082 [==============================] - 43s 40ms/step - loss: 9.1532e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183e3724940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=4, verbose=1, shuffle=False)\n",
    "\n",
    "#Train the model\n",
    "# model.save('LSTM_prediction.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 2s 17ms/step\n",
      "32/32 [==============================] - 1s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.06205074],\n",
       "        [0.06409778],\n",
       "        [0.06244603],\n",
       "        ...,\n",
       "        [0.05743162],\n",
       "        [0.05714814],\n",
       "        [0.0572166 ]],\n",
       "\n",
       "       [[0.06138237],\n",
       "        [0.06404734],\n",
       "        [0.06187846],\n",
       "        ...,\n",
       "        [0.05714814],\n",
       "        [0.0572166 ],\n",
       "        [0.05715768]],\n",
       "\n",
       "       [[0.0614887 ],\n",
       "        [0.06357284],\n",
       "        [0.06208584],\n",
       "        ...,\n",
       "        [0.0572166 ],\n",
       "        [0.05715768],\n",
       "        [0.05710085]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.21135534],\n",
       "        [0.21135534],\n",
       "        [0.21135534],\n",
       "        ...,\n",
       "        [0.21135534],\n",
       "        [0.21135534],\n",
       "        [0.21135534]],\n",
       "\n",
       "       [[0.21135534],\n",
       "        [0.21135534],\n",
       "        [0.21135534],\n",
       "        ...,\n",
       "        [0.21135534],\n",
       "        [0.21135534],\n",
       "        [0.21135534]],\n",
       "\n",
       "       [[0.21135534],\n",
       "        [0.21135534],\n",
       "        [0.21135534],\n",
       "        ...,\n",
       "        [0.21135534],\n",
       "        [0.21135534],\n",
       "        [0.21135534]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=lstm.predict(x_test)\n",
    "\n",
    "y_pred\n",
    "\n",
    "\n",
    "### Lets Do the prediction and check performance metrics\n",
    "# train_predict=model.predict(X_train)\n",
    "# test_predict=model.predict(X_test)\n",
    "\n",
    "# train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ##Transformback to original form\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#train_predict=scaler.inverse_transform(train_predict)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_predict\u001b[38;5;241m=\u001b[39m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_predict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:525\u001b[0m, in \u001b[0;36mMinMaxScaler.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"Undo the scaling of X according to feature_range.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m    Transformed data.\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    523\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 525\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m X \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n\u001b[0;32m    530\u001b[0m X \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:794\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    790\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to convert array of bytes/strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    791\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minto decimal numbers with dtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m--> 794\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m     )\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    800\u001b[0m     _assert_all_finite(array, allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# ##Transformback to original form\n",
    "#train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean_squared_error() got an unexpected keyword argument 'Squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m----> 4\u001b[0m rmse_train\u001b[38;5;241m=\u001b[39m\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_predict\u001b[49m\u001b[43m,\u001b[49m\u001b[43mSquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m rmse_test\u001b[38;5;241m=\u001b[39mmean_squared_error(ytest,test_predict,Squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m mape_train\u001b[38;5;241m=\u001b[39mmean_absolute_percentageerror(y_train,train_predict,Squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: mean_squared_error() got an unexpected keyword argument 'Squared'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse_train=mean_squared_error(y_train,train_predict,Squared=False)\n",
    "\n",
    "rmse_test=mean_squared_error(ytest,test_predict,Squared=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mape_train=mean_absolute_percentageerror(y_train,train_predict,Squared=False)\n",
    "mape_test=mean_absolute_percentageerror(ytest,test_predict,Squared=False)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Rsme on train data:\" ,rmse_train)\n",
    "print(\"Rsme on test data:\",rmse_test)\n",
    "\n",
    "print('mape on train data:',mape_train)\n",
    "print('mape on test data:',mape_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to get better results with the same dataset but a deeper LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50, input_shape=(100,1),\n",
    "               activation='relu', return_sequences=True))\n",
    "\n",
    "model.add(LSTM(50,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOQRZntzqR+VN6yvk667KDe",
   "collapsed_sections": [],
   "mount_file_id": "1H_EbgVwn3ks3qn03FblD5m49UXc70tyN",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
